# -*- coding: utf-8 -*-
"""FastCampus.ipynb

Automatically generated by Colaboratory.

this file needs to be run in 'https://colab.research.google.com/'. 
And Personal_Loan.xlsx must be uploaded in colab repository '/content/'

"""

import math
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

bk = pd.read_excel('/content/Personal_Loan.xlsx', sheet_name=1)

bk

bk.info()

print('Education: ', bk['Education'].unique())
print('Personal Loan: ', bk['Personal Loan'].unique())
print('Securities Account: ', bk['Securities Account'].unique())
print('CD Account: ', bk['CD Account'].unique())
print('Online: ', bk['Online'].unique())
print('CreditCard: ', bk['CreditCard'].unique())

bk.describe().transpose()

bk.duplicated().sum()

bk.columns

bk.columns=['id', 'age', 'exp', 'income', 'zip', 'fam', 'ccavg',
       'edu', 'mort', 'loan', 'secu',
       'cd', 'online', 'cc']

bk1 = bk.drop(['id', 'zip'], axis=1)
bk1.head()

bk2=bk1.groupby('loan')['ccavg'].agg([np.mean, 'count'])
bk2=bk2.rename(columns={'mean': 'CCAvg Mean', 'count': 'Number of People'})
bk2

bk3 = bk1.groupby('fam')['loan'].agg([np.mean, 'count'])
bk3=bk3.rename(columns={'mean':'Personal Loan Mean', 'count':'Number of People'})
bk3

f, ax = plt.subplots(2, 3, figsize=(17, 9))

sns.distplot(bk1['age'], ax=ax[0,0])
sns.distplot(bk1['exp'], ax=ax[0,1])
sns.distplot(bk1['income'], ax=ax[0,2])
sns.distplot(bk1['fam'], ax=ax[1,0])
sns.distplot(bk1['ccavg'], ax=ax[1,1])
sns.distplot(bk1['mort'][bk1['mort']!=0], ax=ax[1,2]) #대다수의 인구가 융자 비율이 0이므로 0을 제외한 나머지에 대한 분포를 알아보자!

plt.show()

def drawline(plt, col):
  mean = bk1.describe().loc['mean', col]
  m25 = bk1.describe().loc['25%', col]
  m50 = bk1.describe().loc['50%', col]
  m75 = bk1.describe().loc['75%', col]
  plt.axvline(mean, color='red', label='mean')
  plt.axvline(m25, color='orange', label='25%')
  plt.axvline(m50, color='blue', label='50%')
  plt.axvline(m75, color='purple', label='75f%')
  plt.legend()

f2, ax2 = plt.subplots(3, 1, figsize=(12, 13))

pp = sns.distplot(bk1['age'], ax=ax2[0], bins=10, color='tomato')
drawline(pp, 'age')
pp = sns.distplot(bk1['exp'], ax=ax2[1], bins=10, color='tomato')
drawline(pp, 'exp')  
pp = sns.distplot(bk1['income'], ax=ax2[2], bins=10, color='tomato')
drawline(pp, 'income')

f3, ax3 = plt.subplots(1, 3, figsize=(16, 6))

sns.violinplot(bk1['loan'], bk1['income'], ax=ax3[0])
sns.violinplot(bk1['loan'], bk1['age'], ax=ax3[1])
sns.violinplot(bk1['loan'], bk1['exp'], ax=ax3[2])

plt.show()

f4, ax4 = plt.subplots(1, 1, figsize=(15, 15))
sns.heatmap(bk1.corr(), ax=ax4, annot=True, fmt='2g')

bk4 = bk1[['ccavg', 'cc', 'loan']]
bk4['ccavg_interval']=pd.cut(bk4['ccavg'], bins=[0, 2, 4, 6, 100], labels =['0-2', '3-4', '5-6', '7~'])
bk4

bk5 = bk4.groupby(['ccavg_interval','cc'])['ccavg'].sum().reset_index()

f5, ax5 =plt.subplots(1, 2, figsize=(16, 6))
sns.barplot(x=bk5['ccavg_interval'], y=bk5['ccavg'], hue=bk5['cc'], palette='cividis', ax=ax5[0])
ax5[0].set(xlabel='Credit card average usage interval', ylabel='Total usage')

sns.scatterplot(data= bk1, x='income', y='ccavg', ax=ax5[1], hue='loan', palette='cividis', alpha=0.6)

import os

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics
import sklearn.preprocessing as preprocessing
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

import statsmodels.api as sm
import itertools
import time

feature_columns = bk1.columns.difference(['loan'])
feature_columns

x = bk1[feature_columns]
y= bk1['loan']

train_x, test_x, train_y, test_y = train_test_split(x, y, stratify=y, train_size=0.7, test_size=0.3, random_state=47)
print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)

scaler = StandardScaler()
train_x = scaler.fit_transform(train_x)
test_x = scaler.fit_transform(test_x)

lrm=LogisticRegression(solver='liblinear', max_iter=2000)

lrm.fit(train_x, train_y)

coef_df = pd.DataFrame(lrm.coef_)
coef_df['intercepet'] = lrm.intercept_
coef_df

training_predict = lrm.predict(train_x)
print("학습 데이터를 넣었을 때의 모델 정확도: {:.4f}".format(metrics.accuracy_score(train_y, training_predict)))

test_predict = lrm.predict(test_x)
print("테스트 데이터를 넣었을 때의 모델 정확도: {:.4f}".format(metrics.accuracy_score(test_y, test_predict)))

logistic_cm = metrics.confusion_matrix(test_y, test_predict, labels=[1, 0])
print(logistic_cm)

lcm_df = pd.DataFrame(logistic_cm, index = [1, 0], columns = ['predict 1', 'predict 0'])
lcm_df

f, ax = plt.subplots(1, 1, figsize=(10, 6))
plt.title("Confusion Matrix for Logistic Regression Model", size = 15)
sns.heatmap(data = lcm_df, annot = True, fmt = 'g', ax=ax)

#True Positive : 대출을 받을 사람을 정확하게 예측 = 93
#True Negative : 대출을 거부할 사람을 정확하게 예측 = 1333
#False Positive : 대출을 받을 것으로 잘못 예측 = 23
#False Negative : 대출을 받지 않을 것으로 잘못 예측 = 51

print("Logistic Regression Model - Classification Report")
print('')
print(metrics.classification_report(test_y, test_predict, labels=[1, 0]))
